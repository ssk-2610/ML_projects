{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DL-Ass02-part4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W87iqgIYZ8en",
        "outputId": "0acbde24-ff0e-4de1-edf2-ffbd1252942b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lvxNzuA-ZwO",
        "outputId": "aa745d68-22cc-40e8-8fd0-76468f4bf795"
      },
      "source": [
        "import os\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer       \n",
        "from nltk.tokenize import TweetTokenizer\n",
        "import re\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense,Dropout,Bidirectional\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.models import load_model "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSN2OhavaPjn"
      },
      "source": [
        "os.chdir('drive/MyDrive/Colab Notebooks/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "machWLzraXUJ",
        "outputId": "9e38ffa0-95e4-427d-d043-6803c48ed974"
      },
      "source": [
        "dataset=pd.read_csv('IMDB Dataset.csv')\n",
        "X=dataset['review']\n",
        "y=dataset['sentiment']\n",
        "y = y.replace('positive', 1)\n",
        "y= y.replace('negative', 0)\n",
        "\n",
        "#cleaning\n",
        "stop=stopwords.words('english')\n",
        "X = X.replace({'<.*?>': ''}, regex = True) \n",
        "X = X.replace({'[^A-Za-z]': ' '}, regex = True)\n",
        "X = X.apply(lambda review: [w for w in review.split() if w not in stop])\n",
        "X = X.apply(lambda review: [w.lower() for w in review])\n",
        "print(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0        [one, reviewers, mentioned, watching, oz, epis...\n",
            "1        [a, wonderful, little, production, the, filmin...\n",
            "2        [i, thought, wonderful, way, spend, time, hot,...\n",
            "3        [basically, family, little, boy, jake, thinks,...\n",
            "4        [petter, mattei, love, time, money, visually, ...\n",
            "                               ...                        \n",
            "49995    [i, thought, movie, right, good, job, it, crea...\n",
            "49996    [bad, plot, bad, dialogue, bad, acting, idioti...\n",
            "49997    [i, catholic, taught, parochial, elementary, s...\n",
            "49998    [i, going, disagree, previous, comment, side, ...\n",
            "49999    [no, one, expects, star, trek, movies, high, a...\n",
            "Name: review, Length: 50000, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "47HLL530afcl",
        "outputId": "b15dec2c-7e19-4069-bfc7-9e0f86a99168"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
        "print(X_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(40000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8cD89zUTak4J"
      },
      "source": [
        "def get_max_length():\n",
        "    review_length = []\n",
        "    for review in X_train:\n",
        "        review_length.append(len(review))\n",
        "\n",
        "    return int(np.ceil(np.mean(review_length)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwFFqVMu0_dJ",
        "outputId": "05341a42-8117-4ad9-c1a0-5f03220e1d80"
      },
      "source": [
        "token = Tokenizer(lower=False)   \n",
        "token.fit_on_texts(X_train)\n",
        "X_train = token.texts_to_sequences(X_train)\n",
        "X_test = token.texts_to_sequences(X_test)\n",
        "\n",
        "max_length = get_max_length()\n",
        "\n",
        "X_train = pad_sequences(X_train, maxlen=max_length, padding='post', truncating='post')\n",
        "X_test = pad_sequences(X_test, maxlen=max_length, padding='post', truncating='post')\n",
        "\n",
        "total_words = len(token.word_index) + 1  \n",
        "print(X_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(40000, 131)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "DT13cLSi1chB",
        "outputId": "7d2ce8fe-a021-4776-e499-0856b1f892c2"
      },
      "source": [
        "EMBED_DIM = 32\n",
        "LSTM_OUT = 64\n",
        "\n",
        "model=Sequential()\n",
        "model.add(Embedding(total_words, EMBED_DIM, input_length = max_length))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(LSTM(LSTM_OUT,return_sequences=True,input_shape=(40000,130)))\n",
        "model.add(LSTM(LSTM_OUT,return_sequences=True))\n",
        "model.add(LSTM(LSTM_OUT,return_sequences=True))\n",
        "model.add(LSTM(LSTM_OUT))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 131, 32)           2952864   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 131, 32)           0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 131, 64)           24832     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 131, 64)           33024     \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 131, 64)           33024     \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 64)                33024     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 3,076,833\n",
            "Trainable params: 3,076,833\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "17rA0g-f1enc"
      },
      "source": [
        "checkpoint = ModelCheckpoint(\n",
        "    'models/LSTM.h5',\n",
        "    monitor='accuracy',\n",
        "    save_best_only=True,\n",
        "    verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-Q-Psa11sRj",
        "outputId": "667f0623-1b22-482d-c50a-07984dc0700e"
      },
      "source": [
        "model.fit(X_train, y_train,validation_data=(X_test, y_test), batch_size = 128, epochs = 20, callbacks=[checkpoint])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "313/313 [==============================] - 56s 65ms/step - loss: 0.5810 - accuracy: 0.6304 - val_loss: 0.2869 - val_accuracy: 0.8805\n",
            "\n",
            "Epoch 00001: accuracy improved from -inf to 0.75657, saving model to models/LSTM.h5\n",
            "Epoch 2/10\n",
            "313/313 [==============================] - 18s 59ms/step - loss: 0.2077 - accuracy: 0.9240 - val_loss: 0.2923 - val_accuracy: 0.8790\n",
            "\n",
            "Epoch 00002: accuracy improved from 0.75657 to 0.92160, saving model to models/LSTM.h5\n",
            "Epoch 3/10\n",
            "313/313 [==============================] - 18s 58ms/step - loss: 0.1148 - accuracy: 0.9634 - val_loss: 0.3085 - val_accuracy: 0.8789\n",
            "\n",
            "Epoch 00003: accuracy improved from 0.92160 to 0.95875, saving model to models/LSTM.h5\n",
            "Epoch 4/10\n",
            "313/313 [==============================] - 18s 58ms/step - loss: 0.0770 - accuracy: 0.9774 - val_loss: 0.4868 - val_accuracy: 0.8747\n",
            "\n",
            "Epoch 00004: accuracy improved from 0.95875 to 0.97355, saving model to models/LSTM.h5\n",
            "Epoch 5/10\n",
            "313/313 [==============================] - 19s 59ms/step - loss: 0.0594 - accuracy: 0.9836 - val_loss: 0.4783 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00005: accuracy improved from 0.97355 to 0.98123, saving model to models/LSTM.h5\n",
            "Epoch 6/10\n",
            "313/313 [==============================] - 18s 59ms/step - loss: 0.0483 - accuracy: 0.9860 - val_loss: 0.4844 - val_accuracy: 0.8704\n",
            "\n",
            "Epoch 00006: accuracy improved from 0.98123 to 0.98252, saving model to models/LSTM.h5\n",
            "Epoch 7/10\n",
            "313/313 [==============================] - 18s 59ms/step - loss: 0.0427 - accuracy: 0.9883 - val_loss: 0.5629 - val_accuracy: 0.8685\n",
            "\n",
            "Epoch 00007: accuracy improved from 0.98252 to 0.98670, saving model to models/LSTM.h5\n",
            "Epoch 8/10\n",
            "313/313 [==============================] - 18s 58ms/step - loss: 0.0384 - accuracy: 0.9890 - val_loss: 0.5709 - val_accuracy: 0.8665\n",
            "\n",
            "Epoch 00008: accuracy improved from 0.98670 to 0.98820, saving model to models/LSTM.h5\n",
            "Epoch 9/10\n",
            "313/313 [==============================] - 18s 58ms/step - loss: 0.0311 - accuracy: 0.9913 - val_loss: 0.5058 - val_accuracy: 0.8660\n",
            "\n",
            "Epoch 00009: accuracy improved from 0.98820 to 0.99030, saving model to models/LSTM.h5\n",
            "Epoch 10/10\n",
            "313/313 [==============================] - 18s 59ms/step - loss: 0.0321 - accuracy: 0.9916 - val_loss: 0.6809 - val_accuracy: 0.8628\n",
            "\n",
            "Epoch 00010: accuracy improved from 0.99030 to 0.99090, saving model to models/LSTM.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fade37ae350>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uBXyhs12Eeh",
        "outputId": "aacde901-92b2-47b6-eae6-8a004c258614"
      },
      "source": [
        "out=model.evaluate(X_train,y_train,verbose=0)\n",
        "print(f'Train accuracy {out[1]*100}%')\n",
        "out=model.evaluate(X_test,y_test,verbose=0)\n",
        "print(f'Test accuracy {out[1]*100}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train accuracy 99.69249963760376%\n",
            "Test accuracy 86.28000020980835%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}